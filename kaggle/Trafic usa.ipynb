{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('C:\\\\Users\\\\ESHOP\\\\Documents\\\\Kaggle Practice Project\\\\Datasets\\\\US_Accidents_March23.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7728394 entries, 0 to 7728393\n",
      "Data columns (total 46 columns):\n",
      " #   Column                 Dtype  \n",
      "---  ------                 -----  \n",
      " 0   ID                     object \n",
      " 1   Source                 object \n",
      " 2   Severity               int64  \n",
      " 3   Start_Time             object \n",
      " 4   End_Time               object \n",
      " 5   Start_Lat              float64\n",
      " 6   Start_Lng              float64\n",
      " 7   End_Lat                float64\n",
      " 8   End_Lng                float64\n",
      " 9   Distance(mi)           float64\n",
      " 10  Description            object \n",
      " 11  Street                 object \n",
      " 12  City                   object \n",
      " 13  County                 object \n",
      " 14  State                  object \n",
      " 15  Zipcode                object \n",
      " 16  Country                object \n",
      " 17  Timezone               object \n",
      " 18  Airport_Code           object \n",
      " 19  Weather_Timestamp      object \n",
      " 20  Temperature(F)         float64\n",
      " 21  Wind_Chill(F)          float64\n",
      " 22  Humidity(%)            float64\n",
      " 23  Pressure(in)           float64\n",
      " 24  Visibility(mi)         float64\n",
      " 25  Wind_Direction         object \n",
      " 26  Wind_Speed(mph)        float64\n",
      " 27  Precipitation(in)      float64\n",
      " 28  Weather_Condition      object \n",
      " 29  Amenity                bool   \n",
      " 30  Bump                   bool   \n",
      " 31  Crossing               bool   \n",
      " 32  Give_Way               bool   \n",
      " 33  Junction               bool   \n",
      " 34  No_Exit                bool   \n",
      " 35  Railway                bool   \n",
      " 36  Roundabout             bool   \n",
      " 37  Station                bool   \n",
      " 38  Stop                   bool   \n",
      " 39  Traffic_Calming        bool   \n",
      " 40  Traffic_Signal         bool   \n",
      " 41  Turning_Loop           bool   \n",
      " 42  Sunrise_Sunset         object \n",
      " 43  Civil_Twilight         object \n",
      " 44  Nautical_Twilight      object \n",
      " 45  Astronomical_Twilight  object \n",
      "dtypes: bool(13), float64(12), int64(1), object(20)\n",
      "memory usage: 2.0+ GB\n",
      "None\n",
      "           Severity     Start_Lat     Start_Lng       End_Lat       End_Lng  \\\n",
      "count  7.728394e+06  7.728394e+06  7.728394e+06  4.325632e+06  4.325632e+06   \n",
      "mean   2.212384e+00  3.620119e+01 -9.470255e+01  3.626183e+01 -9.572557e+01   \n",
      "std    4.875313e-01  5.076079e+00  1.739176e+01  5.272905e+00  1.810793e+01   \n",
      "min    1.000000e+00  2.455480e+01 -1.246238e+02  2.456601e+01 -1.245457e+02   \n",
      "25%    2.000000e+00  3.339963e+01 -1.172194e+02  3.346207e+01 -1.177543e+02   \n",
      "50%    2.000000e+00  3.582397e+01 -8.776662e+01  3.618349e+01 -8.802789e+01   \n",
      "75%    2.000000e+00  4.008496e+01 -8.035368e+01  4.017892e+01 -8.024709e+01   \n",
      "max    4.000000e+00  4.900220e+01 -6.711317e+01  4.907500e+01 -6.710924e+01   \n",
      "\n",
      "       Distance(mi)  Temperature(F)  Wind_Chill(F)   Humidity(%)  \\\n",
      "count  7.728394e+06    7.564541e+06   5.729375e+06  7.554250e+06   \n",
      "mean   5.618423e-01    6.166329e+01   5.825105e+01  6.483104e+01   \n",
      "std    1.776811e+00    1.901365e+01   2.238983e+01  2.282097e+01   \n",
      "min    0.000000e+00   -8.900000e+01  -8.900000e+01  1.000000e+00   \n",
      "25%    0.000000e+00    4.900000e+01   4.300000e+01  4.800000e+01   \n",
      "50%    3.000000e-02    6.400000e+01   6.200000e+01  6.700000e+01   \n",
      "75%    4.640000e-01    7.600000e+01   7.500000e+01  8.400000e+01   \n",
      "max    4.417500e+02    2.070000e+02   2.070000e+02  1.000000e+02   \n",
      "\n",
      "       Pressure(in)  Visibility(mi)  Wind_Speed(mph)  Precipitation(in)  \n",
      "count  7.587715e+06    7.551296e+06     7.157161e+06       5.524808e+06  \n",
      "mean   2.953899e+01    9.090376e+00     7.685490e+00       8.407210e-03  \n",
      "std    1.006190e+00    2.688316e+00     5.424983e+00       1.102246e-01  \n",
      "min    0.000000e+00    0.000000e+00     0.000000e+00       0.000000e+00  \n",
      "25%    2.937000e+01    1.000000e+01     4.600000e+00       0.000000e+00  \n",
      "50%    2.986000e+01    1.000000e+01     7.000000e+00       0.000000e+00  \n",
      "75%    3.003000e+01    1.000000e+01     1.040000e+01       0.000000e+00  \n",
      "max    5.863000e+01    1.400000e+02     1.087000e+03       3.647000e+01  \n",
      "Severity\n",
      "2    6156981\n",
      "3    1299337\n",
      "4     204710\n",
      "1      67366\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Initial EDA and Preprocessing\n",
    "print(df.info())\n",
    "print(df.describe())\n",
    "print(df['Severity'].value_counts()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values by dropping columns with a high percentage of missing values\n",
    "df = df.dropna(thresh=len(df)*0.5, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle remaining missing values with median or mode imputation\n",
    "df.fillna(df.median(numeric_only=True), inplace=True)\n",
    "df.fillna(df.mode().iloc[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Feature Engineering - Date and Time Features\n",
    "# Convert 'Start_Time' column to datetime with robust parsing options\n",
    "df['Start_Time'] = pd.to_datetime(df['Start_Time'], format='ISO8601', errors='coerce')\n",
    "\n",
    "# Verify conversion and check for any NaT values (null values after coercion)\n",
    "print(df['Start_Time'].isnull().sum())\n",
    "\n",
    "df['Hour'] = df['Start_Time'].dt.hour\n",
    "df['DayOfWeek'] = df['Start_Time'].dt.dayofweek\n",
    "df['Month'] = df['Start_Time'].dt.month\n",
    "\n",
    "# Drop the original datetime columns to avoid redundancy\n",
    "df = df.drop(columns=['Start_Time', 'End_Time'], errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# Step 1: Identify high-cardinality categorical columns\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "high_cardinality_cols = [col for col in categorical_cols if df[col].nunique() > 100]\n",
    "\n",
    "# Step 2: Apply target or ordinal encoding to high-cardinality columns to reduce memory usage\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "df[high_cardinality_cols] = ordinal_encoder.fit_transform(df[high_cardinality_cols])\n",
    "\n",
    "# Step 3: For remaining low-cardinality columns, apply one-hot encoding\n",
    "low_cardinality_cols = [col for col in categorical_cols if col not in high_cardinality_cols]\n",
    "df = pd.get_dummies(df, columns=low_cardinality_cols, drop_first=True)\n",
    "\n",
    "# Now the dataset should be smaller and more memory-efficient\n",
    "# Take a sample of the data for testing if the full dataset is too large\n",
    "df_sample = df.sample(frac=0.1, random_state=42)  # Use 10% of the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define your features and target variable\n",
    "X = df.drop(columns=['Severity'])  # Replace 'Severity' with your target column\n",
    "y = df['Severity']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Now apply feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training - Random Forest Classifier\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"ROC-AUC Score:\", roc_auc_score(y_test, model.predict_proba(X_test), multi_class='ovr'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance\n",
    "feature_importances = pd.Series(model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(x=feature_importances[:20], y=feature_importances.index[:20])  # Top 20 features\n",
    "plt.title(\"Top 20 Feature Importances in Predicting Severity\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Tuning with GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_model = grid_search.best_estimator_\n",
    "print(\"Best Parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Evaluation with Best Model\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "print(\"Tuned Model Accuracy:\", accuracy_score(y_test, y_pred_best))\n",
    "print(classification_report(y_test, y_pred_best))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
